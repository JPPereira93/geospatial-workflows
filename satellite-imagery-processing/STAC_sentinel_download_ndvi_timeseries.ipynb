{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "## Data Manipulation and Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pylab import *\n",
    "\n",
    "## Geospatial Operations\n",
    "import geopandas as gpd\n",
    "import rioxarray as rio\n",
    "from leafmap import leafmap\n",
    "\n",
    "## Raster Data Cloud Retrieval\n",
    "import pystac_client\n",
    "import stackstac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pystac\n",
    "* Using conda or mamba was taking a long time to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pystac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdd_path = r\"D:\\Geospatial_Pessoal\"\n",
    "aoi_path = fr\"{hdd_path}\\STAC_py\\pedrogao_grande_area_ardida_2017.geojson\"\n",
    "\n",
    "# Load the GeoJSON file\n",
    "with open(aoi_path) as f:\n",
    "    geojson_aoi = json.load(f)\n",
    "\n",
    "# Extract all coordinates from the polygon\n",
    "\n",
    "coordinates = geojson_aoi['features'][0]['geometry']['coordinates'][0]  # Assuming the first feature is the AOI\n",
    "\n",
    "# Define the bounds from the GeoJSON for stacking\n",
    "\n",
    "lon_min = min(coord[0] for coord in coordinates)\n",
    "lat_min = min(coord[1] for coord in coordinates)\n",
    "lon_max = max(coord[0] for coord in coordinates)\n",
    "lat_max = max(coord[1] for coord in coordinates)\n",
    "\n",
    "# Flatten the list of coordinates if you have a polygon (list of lists)\n",
    "points = [(coord[1], coord[0]) for coord in coordinates]  # (lat, lon) tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2017-01-01\" \n",
    "end_date = \"2017-07-31\"\n",
    "time_range = f\"{start_date}/{end_date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Sentinel 2 level 2 Images with cloud filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_search_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "sentinel_stac_client = pystac_client.Client.open(sentinel_search_url)\n",
    "\n",
    "items = sentinel_stac_client.search(\n",
    "    intersects=geojson_aoi['features'][0]['geometry'],  # Use the geometry directly\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=time_range,\n",
    "    query={\"eo:cloud_cover\": {\"lte\": 10}}  # Filter by cloud coverage. lte = less than or equal to\n",
    ").item_collection()\n",
    "\n",
    "print(\"Number of items found:\", len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_stack = stackstac.stack(items, assets=[\"red\", \"nir\", \"blue\", \"scl\"],\n",
    "                          gdal_env=stackstac.DEFAULT_GDAL_ENV.updated(\n",
    "                               {'GDAL_HTTP_MAX_RETRY': 3,\n",
    "                                'GDAL_HTTP_RETRY_DELAY': 5,\n",
    "                               }),\n",
    "                          epsg=4326, chunksize=(1, 1, 50, 50)).to_dataset(\n",
    "       dim='band')\n",
    "\n",
    "# This length number represents the number  of assets (bands) that are to be extracted\n",
    "# len(sentinel_stack)\n",
    "\n",
    "sentinel_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download S2 dataset if required\n",
    "* Sentinel 2 imagery is downloaded by asset, meaning as separate tiffs for red and nir bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_asset(asset_url, local_path):\n",
    "    try:\n",
    "        response = requests.get(asset_url, stream=True)\n",
    "        response.raise_for_status()  # Raises an error for bad responses\n",
    "        \n",
    "        # Get total file size for progress tracking\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        # Create a tqdm progress bar\n",
    "        with open(local_path, 'wb') as f:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True, desc=local_path, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} | {rate_fmt}]') as bar:\n",
    "                downloaded_size = 0\n",
    "                start_time = time.time()  # Start time for speed calculation\n",
    "                \n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                    downloaded_size += len(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "                    \n",
    "                    # Calculate elapsed time and download speed\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    if elapsed_time > 0:\n",
    "                        speed = downloaded_size / elapsed_time  # bytes per second\n",
    "                        bar.set_postfix(speed=f\"{speed / 1024:.2f} kB/s\")  # Display speed in kB/s\n",
    "        \n",
    "        print(f\"\\nDownloaded: {local_path}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download: {asset_url}, error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading {asset_url}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = fr\"{hdd_path}\\STAC_py\\output\" \n",
    "\n",
    "assets_to_download = [\"red\", \"nir\", \"blue\", \"scl\"]  # Changed from B04 to red, B08 to nir\n",
    "\n",
    "for item in items: \n",
    "    # Print the item ID and available assets for debugging\n",
    "    print(f\"Processing item: {item.id}\")\n",
    "    print(\"Available assets:\", item.assets.keys())  # Print available asset names\n",
    "\n",
    "    for asset_name in assets_to_download:\n",
    "        if asset_name in item.assets:\n",
    "            asset_url = item.assets[asset_name].href\n",
    "            print(f\"Downloading {asset_name} from {asset_url}\")  # Print the URL being downloaded\n",
    "            local_filename = os.path.join(output_directory, f\"{item.id}_{asset_name}.tif\")\n",
    "            download_asset(asset_url, local_filename)\n",
    "        else:\n",
    "            print(f\"Asset {asset_name} not found in item {item.id}\")\n",
    "\n",
    "print(\"All downloads completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_stack['ndvi'] = xr.where(\n",
    "    (sentinel_stack['nir'] + sentinel_stack['red']) != 0,\n",
    "    (sentinel_stack['nir'] - sentinel_stack['red']) / (sentinel_stack['nir'] + sentinel_stack['red']),\n",
    "    np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EVI\n",
    "\n",
    "* evi = G * ((nir -r) / (nir + C1 * R - C2 * B +L)\n",
    "* for sentinel 2: evi = 2.5 * ((nir - red)) / (nir + 6 * red - 7.5 * blue + 1)\n",
    "* Source: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/evi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evi = G * ((nir -r) / (nir + C1 * R - C2 * B +L)\n",
    "\n",
    "# for sentinel 2\n",
    "## evi = 2.5 * ((nir - red)) / (nir + 6 * red - 7.5 * blue + 1)\n",
    "## https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/evi/\n",
    "\n",
    "\n",
    "sentinel_stack['evi'] = xr.where(\n",
    "    (sentinel_stack['nir'] + 6 * sentinel_stack['red'] - 7.5 * sentinel_stack['blue'] + 1) != 0, # Ensure denominator is not zero\n",
    "    2.5 * (sentinel_stack['nir'] - sentinel_stack['red']) /\n",
    "    (sentinel_stack['nir'] + 6 * sentinel_stack['red'] - 7.5 * sentinel_stack['blue'] + 1),\n",
    "    np.nan  \n",
    ")\n",
    "\n",
    "# Remove attributes that are not time, y or x\n",
    "sentinel_stack = sentinel_stack.drop_vars([c for c in sentinel_stack.coords if not (c in ['time', 'y', 'x', 'ndvi'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Coordinate Reference System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(fr\"{hdd_path}/STAC_py/pedrogao_grande_area_ardida_2017.geojson\")\n",
    "\n",
    "crs = \"EPSG:4326\"\n",
    "crs_number = crs[5:]\n",
    "sentinel_stack = sentinel_stack.rio.write_crs(fr\"{crs}\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch export NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sentinel_stack.sizes['time']):\n",
    "    # Extract the timestamp and format it as YYYYMMDD\n",
    "    time_str = str(sentinel_stack['time'].isel(time=i).dt.strftime('%Y%m%d').values)\n",
    "\n",
    "    ndvi_slice = sentinel_stack['ndvi'].isel(time=i)\n",
    "    ndvi_slice = ndvi_slice.fillna(-9999)\n",
    "    ndvi_slice = ndvi_slice.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n",
    "    ndvi_clipped = ndvi_slice.rio.clip(aoi.geometry, aoi.crs, drop=True)\n",
    "    ndvi_clipped.rio.write_nodata(-9999, inplace=True)\n",
    "\n",
    "    output_path = f\"{hdd_path}/STAC_py/ndvi_output/NDVI_{time_str}_{crs_number}.tiff\"\n",
    "    ndvi_clipped.rio.to_raster(output_path)\n",
    "\n",
    "    print(f\"Exported clipped NDVI time slice for {time_str} to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate all band values for the first polygon vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point = points[0]\n",
    "y, x = first_point\n",
    "sentinel_point = sentinel_stack.interp(x=x, y=y, method=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for x and y bounds for the first point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentinel_stack.rio.crs)\n",
    "\n",
    "# Check the bounds of the sentinel_stack\n",
    "x_min, x_max = sentinel_stack.x.min().values, sentinel_stack.x.max().values\n",
    "y_min, y_max = sentinel_stack.y.min().values, sentinel_stack.y.max().values\n",
    "\n",
    "print(f\"x bounds: {x_min} to {x_max}\")\n",
    "print(f\"y bounds: {y_min} to {y_max}\")\n",
    "\n",
    "# Check if the point is within the bounds\n",
    "if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "    print(\"Point is within the bounds of the dataset.\")\n",
    "else:\n",
    "    print(\"Point is outside the dataset bounds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy load the selected data subset and filter NDVI and EVI vegetation indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_point.load()\n",
    "\n",
    "# Transform the xarray Dataset to a DataFrame\n",
    "sentinel_table = sentinel_point.to_dataframe()\n",
    "\n",
    "# Filter NDVI and EVI values that are out of the valid range (-1 to 1)\n",
    "sentinel_table = sentinel_table[\n",
    "    (sentinel_table['ndvi'] >= -1) & (sentinel_table['ndvi'] <= 1) &\n",
    "    (sentinel_table['evi'] >= -1) & (sentinel_table['evi'] <= 1)\n",
    "]\n",
    "# Reset index if needed (optional)\n",
    "sentinel_table.reset_index(inplace=True)\n",
    "\n",
    "sentinel_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "sentinel_table['ndvi'].plot(label='NDVI', marker='o', linestyle='-', markersize=2) \n",
    "sentinel_table['evi'].plot(label='EVI', marker='o', linestyle='-', markersize=2)\n",
    "\n",
    "\n",
    "plt.title(f\"NDVI and EVI Time Series for ({y:.6f}, {x:.6f})\")  # Display coordinates with 6 decimal places\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('NDVI')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Format x-axis date labels using the 'time' column for the ticks\n",
    "\n",
    "plt.xticks(ticks=range(len(sentinel_table)), labels=sentinel_table['time'].dt.strftime('%Y-%m-%d'), rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webmap integration with leafmap\n",
    "* Dinamically see the NDVI timeseries in the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170105_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170108_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170115_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170118_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170125_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170309_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170316_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170405_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170702_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170712_4326.tiff',\n",
       " 'D:\\\\Geospatial_Pessoal\\\\STAC_py\\\\ndvi_output\\\\NDVI_20170724_4326.tiff']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = leafmap.Map(basemap='Google Satellite')\n",
    "\n",
    "ndvi_folder = r\"D:\\Geospatial_Pessoal\\STAC_py\\ndvi_output\"\n",
    "ndvi_images = glob.glob(os.path.join(ndvi_folder, \"*.tiff\"))\n",
    "\n",
    "# Sort images by ascending timeframe\n",
    "ndvi_images.sort()\n",
    "ndvi_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170105',\n",
       " '20170108',\n",
       " '20170115',\n",
       " '20170118',\n",
       " '20170125',\n",
       " '20170309',\n",
       " '20170316',\n",
       " '20170405',\n",
       " '20170702',\n",
       " '20170712',\n",
       " '20170724']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndvi_filenames = []\n",
    "\n",
    "for path in ndvi_images:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    filename = filename.split('NDVI_')[1]\n",
    "    filename = filename.split('_4326')[0] \n",
    "    ndvi_filenames.append(filename)\n",
    "\n",
    "ndvi_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_time_slider(\n",
    "    ndvi_images,\n",
    "    labels = ndvi_filenames, # Add this argument this to reduce the layer filename size  \n",
    "    time_interval = 1.5,\n",
    "    position=\"bottomright\",\n",
    "    band=[1], \n",
    "    zoom_to_layer=True,\n",
    "    cmap=\"RdYlGn\",  min=0, max=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#a50026', '#f88e52', '#fefebd', '#84ca66', '#006837']\n"
     ]
    }
   ],
   "source": [
    "cmap_name = \"RdYlGn\"\n",
    "num_colors = 5\n",
    "\n",
    "# Create the colormap\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "# Sample colors from the colormap\n",
    "colors = [cmap(i / (num_colors - 1)) for i in range(num_colors)]\n",
    "\n",
    "# Convert colors to hexadecimal\n",
    "colors = ['#{:02x}{:02x}{:02x}'.format(int(r * 255), int(g * 255), int(b * 255)) for r, g, b, _ in colors]\n",
    "\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1776ecaf81482a8234a5b2b5ecbbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.840581, -8.9358585], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\"]\n",
    "\n",
    "m.add_legend(\n",
    "    title=\"NDVI Values\",\n",
    "    labels=labels, \n",
    "    colors=colors,\n",
    "    )\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
